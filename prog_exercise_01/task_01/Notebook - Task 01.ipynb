{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e3ea5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Machine Learning Assignment - Exercise 01\n",
    "# Prof. Klaus Berberich\n",
    "# Students:\n",
    "# Aaron Dassen\n",
    "# Jan Beckhausen\n",
    "# Germain Girndt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bdd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS AND DEFINITIONS ONLY\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def analyze_feature_individually(feature):\n",
    "    feature_mean = feature.mean()\n",
    "    feature_variance = feature.var()\n",
    "    \n",
    "    print(f\"Analyzed Feature: {acronym_to_name.get(feature.name)}\")\n",
    "    print(f\"Mean Value: {feature_mean:.2f}\")\n",
    "    print(f\"Variance: {feature_variance:.2f}\\n\")\n",
    "\n",
    "def analyze_features_jointly(feature_one, feature_two):\n",
    "    pearsons_correlation = feature_one.corr(feature_two, method='pearson')\n",
    "    covariance = feature_one.cov(feature_two)\n",
    "\n",
    "    print(f\"Covariance: {covariance:.2f}\")\n",
    "    print(f\"Pearson's Correlation: {pearsons_correlation:.2f}\")\n",
    "    \n",
    "def create_figure(feature_x, feature_y):\n",
    "    title = f\"{acronym_to_name.get(feature_x.name)} x {acronym_to_name.get(feature_y.name)}\"\n",
    "    figure = plt.figure()\n",
    "    ax = figure.add_subplot(111)\n",
    "    \n",
    "    color = np.abs(feature_x) + np.abs(feature_y)\n",
    "    ax.scatter(feature_x, feature_y, c=color, cmap='plasma')\n",
    "    ax.set_xlabel(acronym_to_name.get(feature_x.name))\n",
    "    ax.set_ylabel(acronym_to_name.get(feature_y.name))\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    return figure\n",
    "    \n",
    "\n",
    "def create_figure_with_regression_line(feature_x, feature_y, w0_star, w1_star):\n",
    "    figure = create_figure(feature_x, feature_y)\n",
    "    ax = figure.get_axes()[0]\n",
    "    regression_line_y = w0_star + w1_star * feature_x\n",
    "    ax.plot(feature_x, regression_line_y, color='red', label='Regression Line')\n",
    "    ax.legend()\n",
    "    \n",
    "    return figure\n",
    "\n",
    "    \n",
    "# Load the data\n",
    "PATH_TO_DATA=\"/Users/germaingirndt/source/machine_learning/prog_exercise_01/task_01/kaggle/Spotify 2010 - 2019 Top 100.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b70de2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acronym_to_name = {\n",
    "    \"bpm\": \"Beats per Minute (bpm)\",\n",
    "    \"nrgy\": \"Energy (ngry)\",\n",
    "    \"dnce\": \"Danceability (dnce)\",\n",
    "    \"val\": \"Mood (val)\",\n",
    "    \"pop\": \"Popularity (pop)\"\n",
    "}\n",
    "\n",
    "# Setting variables used by the following snippets\n",
    "feature_names = [\"pop\", \"top genre\", \"bpm\", \"nrgy\", \"dnce\", \"val\"]\n",
    "\n",
    "features_df = data[feature_names]\n",
    "pop_series = features_df.get(\"pop\")\n",
    "genre_series = features_df.get(\"top genre\")\n",
    "\n",
    "other_features_df = features_df[feature_names[2:]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cbe0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Taking a look at the data\n",
    "\n",
    "df_cleaned = features_df.copy()\n",
    "df_cleaned.dropna(inplace=True)\n",
    "\n",
    "df_cleaned.describe(include=\"all\").round(2)\n",
    "\n",
    "# Note: The NaNs are not representative;\n",
    "# They're simply caused by trying to output numeric statical coefficients for non-numeric values and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c08f24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6dfc94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1.1a - Create scatter plots and compute Pearson's correlation coefficients\n",
    "for _, feature_series in other_features_df.items():\n",
    "    \n",
    "    create_figure(feature_series, pop_series)\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "    analyze_feature_individually(pop_series)\n",
    "    analyze_feature_individually(feature_series)\n",
    "    analyze_features_jointly(pop_series, feature_series)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b9d67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1.1b - Ordinary Least Squares:\n",
    "# Determine optimal coeficients, add a regression line to the plot, compute mean squared error (MSE)\n",
    "\n",
    "for _, feature_series in other_features_df.items():\n",
    "    \n",
    "    # Defining X and Y\n",
    "    Y = pop_series\n",
    "    X = feature_series\n",
    "\n",
    "\n",
    "    # Dropping rows where either Y or X have NaNs\n",
    "    df = pd.DataFrame({Y.name: Y, X.name: X}).dropna(how='any')\n",
    "\n",
    "    filtered_Y = df.get(Y.name)\n",
    "    filtered_X = df.get(X.name)\n",
    "\n",
    "    # Making sure that both variables have the same size\n",
    "    treated_Y = filtered_Y[0:len(filtered_X)]\n",
    "    # Converting 1d matrix into a 2d matrix (required by the model.fit() method)\n",
    "    treated_X = filtered_X.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    # Creating a linear regression model and fitting it to the data\n",
    "    model = LinearRegression()\n",
    "    model.fit(treated_X, treated_Y)\n",
    "    \n",
    "    # Separating coeficients\n",
    "    w0_star = model.intercept_\n",
    "    w1_star = model.coef_[0]\n",
    "\n",
    "\n",
    "    # Calculating the mean squared error (MSE)\n",
    "    mse = sum((model.predict(treated_X) - treated_Y)**2) / len(treated_Y) \n",
    "    \n",
    "    # Ploting chart\n",
    "    create_figure_with_regression_line(X, Y, w0_star, w1_star)\n",
    "    plt.show()\n",
    "    \n",
    "    # Printing Info\n",
    "    print(f\"Feature: {acronym_to_name.get(X.name)}\")\n",
    "    print(f\"w0*: {w0_star}\")\n",
    "    print(f\"w1*: {w1_star}\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727d79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.c - Multiple linear regression\n",
    "# Model for all features (including the nominal feature genre)\n",
    "# Randomly split data into training (80%) and test (20%)\n",
    "# Determine optimal coefficients for the training and mean squared error for the test data\n",
    "\n",
    "\n",
    "def print_multiple_linear_regression_test(X, Y):\n",
    "    # Splitting into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2023)\n",
    "\n",
    "\n",
    "    # Creating a linear regression model and fitting it to the data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    w0_star = model.intercept_\n",
    "    w1_until_n_star = model.coef_\n",
    "\n",
    "\n",
    "    # Calculating the mean squared error (MSE)\n",
    "    mse = sum((model.predict(X_test) - y_test)**2) / len(y_test)\n",
    "\n",
    "    print(f\"Results:\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"w0*: {w0_star}\")\n",
    "    print(f\"w1...n*: {w1_until_n_star}\")\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Droping rows where either Y or X have NaNs\n",
    "def clean_na(X, Y):\n",
    "    df = pd.concat([X, Y], axis=1).dropna(how='any')\n",
    "\n",
    "    cleaned_Y_series = df.get(Y.name)\n",
    "    cleaned_X_df = df.loc[:, df.columns != Y.name]\n",
    "    \n",
    "    return [cleaned_X_df, cleaned_Y_series]\n",
    "\n",
    "def merge_less_frequent_genres(one_hot_encoded_genre):\n",
    "\n",
    "    # Minimum number of occurrences to keep the genre category as is\n",
    "    number_of_data_points = one_hot_encoded_genre.shape[0]\n",
    "    genre_threshold =  number_of_data_points * 0.005\n",
    "\n",
    "    # Initialize a new category to group less frequent genres\n",
    "    other_genre_category = \"_others\"\n",
    "    \n",
    "    \n",
    "    # Identify genre categories with less than the threshold\n",
    "    genre_counts = one_hot_encoded_genre[one_hot_encoded_genre.columns].sum()\n",
    "    less_frequent_genres = genre_counts[genre_counts < genre_threshold].index.tolist()\n",
    "\n",
    "    # Group less frequent genres into the \"other\" category\n",
    "    if less_frequent_genres:\n",
    "        one_hot_encoded_genre[other_genre_category] = one_hot_encoded_genre[less_frequent_genres].max(axis=1)\n",
    "        one_hot_encoded_genre.drop(columns=less_frequent_genres, inplace=True)\n",
    "        \n",
    "    return one_hot_encoded_genre\n",
    "\n",
    "def merge_similar_categories(one_hot_encoded_genre):\n",
    "\n",
    "    big_genre_categories = [ \"rock\", \"hip hop\", \"rap\", \"dance\", \"r&b\", \"reggae\", \"electro\", \"indie\", \"wave\", \"house\", \"metal\", \"french\", \"techno\", \"afro\", \"funk\", \"country\", \"latin\", \"pop\"]\n",
    "\n",
    "    for genre_category in big_genre_categories:\n",
    "        # Get all columns names containing the substring genre_category\n",
    "        genre_columns = [col for col in one_hot_encoded_genre.columns if genre_category in col]\n",
    "\n",
    "        # set a new column\n",
    "        one_hot_encoded_genre[\"_\" + genre_category] = 0\n",
    "\n",
    "        # Set the new column's bit for all rows which match rows\n",
    "        has_row_any_genre_column_set_as_true = one_hot_encoded_genre[genre_columns].any(axis=1)\n",
    "        one_hot_encoded_genre.loc[has_row_any_genre_column_set_as_true, \"_\" + genre_category] = 1\n",
    "        \n",
    "        # Drop the original genre columns\n",
    "        other_columns = list(filter( lambda x : x != genre_category, genre_columns))\n",
    "\n",
    "        one_hot_encoded_genre.drop(columns=genre_columns, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    return one_hot_encoded_genre\n",
    "        \n",
    "        \n",
    "print(\"Multiple linear regression WITHOUT one hot encoding (good results)\")\n",
    "Y = pop_series.copy()\n",
    "X = other_features_df.copy()\n",
    "[X, Y] = clean_na(X, Y)\n",
    "print_multiple_linear_regression_test(X, Y)\n",
    "\n",
    "print(\"Multiple linear regression WITH one hot encoding (worst results)\")\n",
    "one_hot_encoded_genre = pd.get_dummies(genre_series) # One hot encoding for genre\n",
    "one_hot_encoded_genre.rename(columns={\"pop\": \"_pop music\"}, inplace=True) # renaming the column 'pop' genre for avoiding colision with the feature pop\n",
    "\n",
    "Y = pop_series.copy()\n",
    "X = pd.concat([other_features_df.copy(), one_hot_encoded_genre.copy()], axis=1)\n",
    "[X, Y] = clean_na(X, Y)\n",
    "print_multiple_linear_regression_test(X, Y)\n",
    "\n",
    "\n",
    "print(\"Multiple linear regression WITH TREATED one hot encoding (best results!!!)\")\n",
    "treated_one_hot_encoded_genre = merge_less_frequent_genres(merge_similar_categories(one_hot_encoded_genre.copy()))\n",
    "\n",
    "\n",
    "Y = pop_series.copy()\n",
    "X = pd.concat([other_features_df.copy(), treated_one_hot_encoded_genre.copy()], axis=1)\n",
    "[X, Y] = clean_na(X, Y)\n",
    "\n",
    "print_multiple_linear_regression_test(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d604b62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding visualization:\n",
    "print(\"One hot encoded WITHOUT treatement:\\n\")\n",
    "print(\"\\n\\n\\nCategory count:\")\n",
    "print(one_hot_encoded_genre.sum())\n",
    "print(\"\\n\\n\\Description:\")\n",
    "print(one_hot_encoded_genre.describe(include=\"all\").round(2))\n",
    "\n",
    "print(\"One hot encoded WITH treatment:\\n\")\n",
    "print(\"\\n\\n\\nCategory count:\")\n",
    "print(treated_one_hot_encoded_genre.sum())\n",
    "print(\"\\n\\n\\Description:\")\n",
    "print(treated_one_hot_encoded_genre.describe(include=\"all\").round(2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e1b22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d34b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draft 1 (Not part of the exercise)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Generate fake data\n",
    "np.random.seed(1)\n",
    "num_points = 100\n",
    "\n",
    "# Create a list of points\n",
    "points = []\n",
    "for _ in range(num_points):\n",
    "    point = {\n",
    "        'x': np.random.normal(0, 1),\n",
    "        'y': np.random.normal(0, 1),\n",
    "        'z': np.random.normal(0, 1)\n",
    "    }\n",
    "    points.append(point)\n",
    "\n",
    "# Create scatterplot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for point in points:\n",
    "    ax.scatter(point.get(\"x\"), point.get(\"y\"), point.get(\"z\"), color=\"red\", marker=\"x\")\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b30da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draft 2 (Not part of the exercise)\n",
    "\n",
    "\n",
    "# Defining X and Y\n",
    "Y = pop_series\n",
    "X = other_features_df.iloc[:, 1]\n",
    "\n",
    "\n",
    "# Dropping rows where either Y or X have NaNs\n",
    "df = pd.DataFrame({Y.name: Y, X.name: X}).dropna(how='any')\n",
    "    \n",
    "cleaned_Y = df.get(Y.name)\n",
    "cleaned_X = df.get(X.name)\n",
    "Y = cleaned_Y\n",
    "X = cleaned_X\n",
    "\n",
    "\n",
    "\n",
    "def calculate_w1_star(X, Y):\n",
    "    n = len(X)\n",
    "    sigma_x = X.sum()\n",
    "    sigma_y = Y.sum()    \n",
    "    sigma_x_multiplied_by_y = sum([Xi * Yi for Xi, Yi in zip(X, Y)])\n",
    "    sigma_x_squared = sum([Xi ** 2 for Xi in X])\n",
    "\n",
    "    w1_star = ((n * sigma_x_multiplied_by_y) - sigma_x * sigma_y) / (n * sigma_x_squared - sigma_x ** 2)\n",
    "    return w1_star\n",
    "    \n",
    "def calculate_w0_star(X, Y, w1_star):\n",
    "    w0_star = Y.mean() - w1_star * X.mean()\n",
    "    return w0_star\n",
    "    \n",
    "def predict_y(x):\n",
    "    w1_star = calculate_w1_star(X, Y)\n",
    "    w0_star = calculate_w0_star(X, Y, w1_star)\n",
    "    \n",
    "\n",
    "    print(f\"w0*: {w0_star}\")\n",
    "    print(f\"w1*: {w1_star}\")\n",
    "    \n",
    "    return w0_star + w1_star * x\n",
    "\n",
    "\n",
    "\n",
    "predict_y(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
