{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3a14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Assignment - Exercise 02\n",
    "# Prof. Klaus Berberich\n",
    "# Students:\n",
    "# Aaron Dassen (3871517)\n",
    "# Jan Beckhausen (5000902)\n",
    "# Germain Girndt (3872203)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "df = df[['v1', 'v2']] # considering only label and sms text columns\n",
    "df.columns = ['classification', 'message']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a11870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task a - Cleaning up\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split() # convert to list of words\n",
    "    text = [word for word in text if word not in ENGLISH_STOP_WORDS] # stemming and removing stopwords\n",
    "    text = ' '.join(text) # joining words back to form the cleaned text\n",
    "    return text\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub('[^a-zA-Z\\d]', ' ', text) # keeping only alphanumeric characters\n",
    "    text = text.lower() # lowercasing\n",
    "    text = remove_stop_words(text) # removing stop words as recommended in slide 57\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# apply the function on message column\n",
    "df['message'] = df['message'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ed9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9647887323943662\n",
      "Recall:  0.9013157894736842\n",
      "F1 Score:  0.9319727891156462\n"
     ]
    }
   ],
   "source": [
    "# Task b - Train Na√Øve Bayes - Compute Precision, Recall and F1 Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['classification'], test_size=0.2, random_state=2023)\n",
    "\n",
    "# convert text data into numerical data (bag of words)\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train).toarray()\n",
    "X_test = cv.transform(X_test).toarray()\n",
    "\n",
    "# train the model\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# compute precision, recall and f1 score\n",
    "precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d1b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Priors: Spam 0.8665021314785729 | Ham: 0.1334978685214271\n",
      "\n",
      "Top 10 words indicative of spam: \n",
      "Position\tWord\tIndex\tLog Probability\n",
      "1\t\tgt\t3098\t-4.88168549035242\n",
      "2\t\tlt\t4046\t-4.889467630794475\n",
      "3\t\tjust\t3681\t-4.9750595611298785\n",
      "4\t\tok\t4675\t-4.983606621708337\n",
      "5\t\tll\t3962\t-5.045573345457536\n",
      "6\t\tlike\t3915\t-5.136327708726001\n",
      "7\t\tknow\t3766\t-5.166786916210709\n",
      "8\t\tur\t6868\t-5.166786916210709\n",
      "9\t\tcome\t1820\t-5.198203112444088\n",
      "10\t\tgood\t3026\t-5.225158922432616\n",
      "\n",
      "Top 10 words indicative of ham: \n",
      "Position\tWord\tIndex\tLog Probability\n",
      "1\t\tfree\t2838\t-4.588600922224773\n",
      "2\t\ttxt\t6765\t-4.810283552899308\n",
      "3\t\tur\t6868\t-5.011765607432339\n",
      "4\t\tmobile\t4323\t-5.115143961886173\n",
      "5\t\ttext\t6495\t-5.125094292739341\n",
      "6\t\tstop\t6202\t-5.135144628592843\n",
      "7\t\tclaim\t1740\t-5.219404972210583\n",
      "8\t\twww\t7265\t-5.335815324054994\n",
      "9\t\treply\t5451\t-5.360816626260411\n",
      "10\t\tprize\t5161\t-5.412776365191123\n"
     ]
    }
   ],
   "source": [
    "# Task C - Calculate class priors, which means, probability of a class in the data, independent of the features\n",
    "import numpy as np\n",
    "\n",
    "# class priors\n",
    "class_priors = np.exp(classifier.class_log_prior_)\n",
    "print(f\"Class Priors: Spam {class_priors[0]} | Ham: {class_priors[1]}\")\n",
    "\n",
    "# top 10 words indicative of spam and ham\n",
    "spam_feature_log_probs = classifier.feature_log_prob_[0, :]\n",
    "ham_feature_log_probs = classifier.feature_log_prob_[1, :]\n",
    "\n",
    "# getting top 10 words indexes\n",
    "top_spam_words_indexes = np.argsort(spam_feature_log_probs)[-10:][::-1]\n",
    "top_ham_words_indexes = np.argsort(ham_feature_log_probs)[-10:][::-1]\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTop 10 words indicative of spam: \")\n",
    "print(\"Position\\tWord\\tIndex\\tLog Probability\")\n",
    "for position, index in enumerate(top_spam_words_indexes):\n",
    "    corrected_position = position + 1\n",
    "    word = cv.get_feature_names_out()[index]\n",
    "    probability = spam_feature_log_probs[index]\n",
    "    print(f\"{corrected_position}\\t\\t{word}\\t{index}\\t{probability}\")\n",
    "    \n",
    "print(\"\\nTop 10 words indicative of ham: \")\n",
    "print(\"Position\\tWord\\tIndex\\tLog Probability\")\n",
    "for position, index in enumerate(top_ham_words_indexes):\n",
    "    corrected_position = position + 1\n",
    "    word = cv.get_feature_names_out()[index]\n",
    "    probability = ham_feature_log_probs[index]\n",
    "    print(f\"{corrected_position}\\t\\t{word}\\t{index}\\t{probability}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44ddaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.0\n",
      "Recall:  0.28289473684210525\n",
      "F1 Score:  0.441025641025641\n"
     ]
    }
   ],
   "source": [
    "# Task d - kNN, SMS data points encoding, distance measure, precision, recall and F1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Training a k-NN model with k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=7, metric='euclidean') # Using Euclidean distance as distance beasure\n",
    "knn.fit(X_train, y_train) # SMS data points already encoded as bag of words for kNN\n",
    "\n",
    "# Making predictions\n",
    "y_predicted = knn.predict(X_test)\n",
    "\n",
    "# Computing Precision, Recall and F1 Score\n",
    "precision = precision_score(y_true=y_test, y_pred=y_predicted, pos_label='spam')\n",
    "recall = recall_score(y_true=y_test, y_pred=y_predicted, pos_label='spam')\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_predicted, pos_label='spam')\n",
    "\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c26c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
