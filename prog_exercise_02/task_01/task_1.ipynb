{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T14:57:22.762885Z",
     "start_time": "2023-06-11T14:57:22.730889Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Machine Learning Assignment - Exercise 02\n",
    "# Prof. Klaus Berberich\n",
    "# Students:\n",
    "# Aaron Dassen (3871517)\n",
    "# Jan Beckhausen (5000902)\n",
    "# Germain Girndt (3872203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T14:45:59.885624Z",
     "start_time": "2023-06-11T14:44:47.564626Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "# definitions\n",
    "# for part b)\n",
    "logisticRegression = LogisticRegression()\n",
    "# for part c)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "# for d)\n",
    "base_classifier = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Part a)\n",
    "# Separate the features and classes\n",
    "train_features = train_data.iloc[:, 1:].values\n",
    "train_labels = train_data.iloc[:, 0].values\n",
    "test_features = test_data.iloc[:, 1:].values\n",
    "test_labels = test_data.iloc[:, 0].values\n",
    "\n",
    "# Normalizing the pixel values, since they vary from [0, 255] we divide them each by 255\n",
    "train_features = train_features / 255.0\n",
    "test_features = test_features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier: 0.8565\n",
      "Micro-averaged Precision: 0.8565\n",
      "Macro-averaged Precision: 0.8548989719251182\n",
      "Micro-averaged Recall: 0.8565\n",
      "Macro-averaged Recall: 0.8564999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Part b)\n",
    "# Train the classifier that uses the logistic regression method\n",
    "logisticRegression.fit(train_features, train_labels)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "test_predictions = logisticRegression.predict(test_features)\n",
    "\n",
    "# Calculate the accuracy for Log. Regression\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "# Calculate the precision for Log. Regression\n",
    "precision_micro = precision_score(test_labels, test_predictions, average='micro')\n",
    "precision_macro = precision_score(test_labels, test_predictions, average='macro')\n",
    "# Calculate the recall for Log. Regression\n",
    "recall_micro = recall_score(test_labels, test_predictions, average='micro')\n",
    "recall_macro = recall_score(test_labels, test_predictions, average='macro')\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy of the classifier:\", accuracy)\n",
    "print(\"Micro-averaged Precision:\", precision_micro)\n",
    "print(\"Macro-averaged Precision:\", precision_macro)\n",
    "print(\"Micro-averaged Recall:\", recall_micro)\n",
    "print(\"Macro-averaged Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8558\n",
      "Micro-averaged Precision: 0.8558\n",
      "Macro-averaged Precision: 0.8584578704904835\n",
      "Micro-averaged Recall: 0.8558\n",
      "Macro-averaged Recall: 0.8558\n"
     ]
    }
   ],
   "source": [
    "#Part c)\n",
    "# Train the classifier that uses KNN with k=7\n",
    "knn.fit(train_features, train_labels)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "test_predictions = knn.predict(test_features)\n",
    "\n",
    "# Calculate the accuracy for KNN\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "# Calculate the precision for KNN\n",
    "precision_micro = precision_score(test_labels, test_predictions, average='micro')\n",
    "precision_macro = precision_score(test_labels, test_predictions, average='macro')\n",
    "# Calculate the recall for KNN\n",
    "recall_micro = recall_score(test_labels, test_predictions, average='micro')\n",
    "recall_macro = recall_score(test_labels, test_predictions, average='macro')\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Micro-averaged Precision:\", precision_micro)\n",
    "print(\"Macro-averaged Precision:\", precision_macro)\n",
    "print(\"Micro-averaged Recall:\", recall_micro)\n",
    "print(\"Macro-averaged Recall:\", recall_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7205\n",
      "Micro-averaged Precision: 0.7205\n",
      "Macro-averaged Precision: 0.7448523138080523\n",
      "Micro-averaged Recall: 0.7205\n",
      "Macro-averaged Recall: 0.7205\n"
     ]
    }
   ],
   "source": [
    "# Part d)\n",
    "# Create decision trees using bagging\n",
    "ensemble = BaggingClassifier(base_classifier, n_estimators=10)\n",
    "\n",
    "# Fit the features to the model\n",
    "ensemble.fit(train_features, train_labels)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "test_predictions = ensemble.predict(test_features)\n",
    "\n",
    "# Calculate the accuracy for the decision trees\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "# Calculate the precision for the decision trees\n",
    "precision_micro = precision_score(test_labels, test_predictions, average='micro')\n",
    "precision_macro = precision_score(test_labels, test_predictions, average='macro')\n",
    "# Calculate the recall for the decision trees\n",
    "recall_micro = recall_score(test_labels, test_predictions, average='micro')\n",
    "recall_macro = recall_score(test_labels, test_predictions, average='macro')\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Micro-averaged Precision:\", precision_micro)\n",
    "print(\"Macro-averaged Precision:\", precision_macro)\n",
    "print(\"Micro-averaged Recall:\", recall_micro)\n",
    "print(\"Macro-averaged Recall:\", recall_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
